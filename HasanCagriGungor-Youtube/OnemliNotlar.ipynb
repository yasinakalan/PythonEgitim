{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"motor\"] = df[\"motor\"].str.replace(\"L\",\"\")       # motor sütunundaki verilerden \"L\" ifadesi hiçbirşey(\"\") ile değiştirildi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"motor\"] = pd.to_numeric(df[\"motor\"])            # \"L\" atıldıktan sonra sayılar hala string olduğundan bu aşamada float veri tipine dönüştürüldü."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[\"kasa\", \"vites\", \"yakit\"], drop_first=True)      # Bu aşamada kategorik ifadeleri sayısal sorgu verilerine dönüştürdü. Bu sayede her ifade 1 ve 0 gibi rakamlarla ifade edilebilir oldu.\n",
    "\n",
    "\"\"\"\n",
    "drop_first=True --> Bu seçenek eklendiğinde ilk verileri kaldırarak sütun sayısını azaltır. 0 sa vardır ise 1 se yoktur. Ama burada tek veri yeterlidir. 0 olan veri kaldırılır.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns = [\"sinif\", \"saat\", \"puan\"]      # Verisetindeki kolon isimleri güncellendi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/v2/resize:fit:953/1*wpVgt07J_TeH3jEdc3A50g.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NETTEN GÖRÜNTÜ ÇEKME:\n",
    "from IPython.display import display, Image\n",
    "image_url = 'https://miro.medium.com/v2/resize:fit:953/1*wpVgt07J_TeH3jEdc3A50g.png'\n",
    "display(Image(url=image_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HATALARIN TESPİTİ:\n",
    "\n",
    "\"\"\"\n",
    "MSE: MEAN SQUARE ERROR ORTALAMALARIN KARESİ HATASI\n",
    "RMSE: ORTALAMALARIN KARESİNİN KAREKÖKÜNÜN HATASI\n",
    "MAE: MEAN ABSTRACT ERROR\n",
    "MAPE: MEAN ABSTRACT PERCENT ERROR\n",
    "\"\"\"\n",
    "\n",
    "# Kütüphaneleri yükle:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Dataframe yüklenmesi:\n",
    "df = pd.read_csv('insurance.csv')\n",
    "\"\"\"\n",
    "age\tsex\tbmi\tchildren\tsmoker\tregion\tcharges\n",
    "0\t19\tfemale\t27.90\t0\tyes\tsouthwest\t16884.9240\n",
    "1\t18\tmale\t33.77\t1\tno\tsoutheast\t1725.5523\n",
    "2\t28\tmale\t33.00\t3\tno\tsoutheast\t4449.4620\n",
    "\"\"\"\n",
    "\n",
    "# Dataframe veri dönüşümü:\n",
    "df = pd.get_dummies(df, columns=['sex', 'smoker', 'region'], drop_first=True)\n",
    "y = df[['charges']]\n",
    "x = df.drop('charges', axis=1)\n",
    "\n",
    "# Lineer Regresyon modelinin kurulması:\n",
    "lm = LinearRegression()\n",
    "model = lm.fit(x, y)\n",
    "model.score(x, y)\n",
    "model.predict([[19,26,0,1,1,0,0,1]]) # bilinmeyen verilerin tahmini için x değerlerinin tamamı sırasıyla verilir.\n",
    "\n",
    "# Teorik ifadelere göre hataların bulunması:\n",
    "df_hata = pd.DataFrame()\n",
    "df_hata['y_gercek'] = y\n",
    "y_tahmin = model.predict(x)      # y_tahmin değerini bulmak için predict içine dataframe kendisinde bulunan bilinen x değerleri verilir ve oluşan liste sadece y_tahmin verilerini içerir.\n",
    "df_hata['y_tahmin'] = y_tahmin\n",
    "df_hata['error'] = y-y_tahmin\n",
    "# MSE: MEAN SQUARED ERROR: HATA KARELERİ ORTALAMASI\n",
    "df_hata['squared_error'] = df_hata['error']**2\n",
    "# MAE: MEAN ABSTRACT ERROR: MUTLAK DEĞER\n",
    "df_hata['abstract_error'] = np.abs(df_hata['error']) \n",
    "# MAPE: MEAN ABSOLUTE PERCENT ERROR: MUTLAK YÜZDELİK HATA\n",
    "df_hata['absolute_percent_error'] = np.abs((y-y_tahmin)/y)\n",
    "df_hata.mean()\n",
    "\n",
    "# Kütüphane kullanarak hataların bulunması:\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "mean_squared_error(y,y_tahmin)\n",
    "mean_absolute_error(y,y_tahmin)\n",
    "mean_absolute_percentage_error(y, y_tahmin)\n",
    "df_hata.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNDERFITTING: AZ ÖĞRENME\n",
    "# OVERFITTING: AŞIRI UYUM\n",
    "# BALANCEDFITTING: DENGELİ ÖĞRENME\n",
    "\n",
    "# Kütüphaneleri yükleyelim:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "# Dataframe yükle:\n",
    "df = sns.load_dataset('diamonds')\n",
    "\"\"\"\n",
    "carat\tcut\tcolor\tclarity\tdepth\ttable\tprice\tx\ty\tz\n",
    "0\t0.23\tIdeal\tE\tSI2\t61.5\t55.0\t326\t3.95\t3.98\t2.43\n",
    "1\t0.21\tPremium\tE\tSI1\t59.8\t61.0\t326\t3.89\t3.84\t2.31\n",
    "2\t0.23\tGood\tE\tVS1\t56.9\t65.0\t327\t4.05\t4.07\t2.31\n",
    "3\t0.29\tPremium\tI\tVS2\t62.4\t58.0\t334\t4.20\t4.23\t2.63\n",
    "4\t0.31\tGood\tJ\tSI2\t63.3\t58.0\t335\t4.34\t4.35\t2.75\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "53935\t0.72\tIdeal\tD\tSI1\t60.8\t57.0\t2757\t5.75\t5.76\t3.50\n",
    "53936\t0.72\tGood\tD\tSI1\t63.1\t55.0\t2757\t5.69\t5.75\t3.61\n",
    "53937\t0.70\tVery Good\tD\tSI1\t62.8\t60.0\t2757\t5.66\t5.68\t3.56\n",
    "53938\t0.86\tPremium\tH\tSI2\t61.0\t58.0\t2757\t6.15\t6.12\t3.74\n",
    "53939\t0.75\tIdeal\tD\tSI2\t62.2\t55.0\t2757\t5.83\t5.87\t3.64\n",
    "53940 rows × 10 columns\n",
    "\"\"\"\n",
    "\n",
    "# Veriyi Önişleme:\n",
    "df = pd.get_dummies(df, columns=['cut', 'color', 'clarity'], drop_first=True)\n",
    "\"\"\"\n",
    "\tcarat\tdepth\ttable\tprice\tx\ty\tz\tcut_Premium\tcut_Very Good\tcut_Good\t...\tcolor_H\tcolor_I\tcolor_J\tclarity_VVS1\tclarity_VVS2\tclarity_VS1\tclarity_VS2\tclarity_SI1\tclarity_SI2\tclarity_I1\n",
    "0\t0.23\t61.5\t55.0\t326\t3.95\t3.98\t2.43\tFalse\tFalse\tFalse\t...\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\n",
    "1\t0.21\t59.8\t61.0\t326\t3.89\t3.84\t2.31\tTrue\tFalse\tFalse\t...\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\tFalse\n",
    "2\t0.23\t56.9\t65.0\t327\t4.05\t4.07\t2.31\tFalse\tFalse\tTrue\t...\tFalse\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\tFalse\tFalse\tFalse\n",
    "3\t0.29\t62.4\t58.0\t334\t4.20\t4.23\t2.63\tTrue\tFalse\tFalse\t...\tFalse\tTrue\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\tFalse\tFalse\n",
    "4\t0.31\t63.3\t58.0\t335\t4.34\t4.35\t2.75\tFalse\tFalse\tTrue\t...\tFalse\tFalse\tTrue\tFalse\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\n",
    "...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\t...\n",
    "53935\t0.72\t60.8\t57.0\t2757\t5.75\t5.76\t3.50\tFalse\tFalse\tFalse\t...\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\tFalse\n",
    "53936\t0.72\t63.1\t55.0\t2757\t5.69\t5.75\t3.61\tFalse\tFalse\tTrue\t...\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\tFalse\n",
    "53937\t0.70\t62.8\t60.0\t2757\t5.66\t5.68\t3.56\tFalse\tTrue\tFalse\t...\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\tFalse\n",
    "53938\t0.86\t61.0\t58.0\t2757\t6.15\t6.12\t3.74\tTrue\tFalse\tFalse\t...\tTrue\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\n",
    "53939\t0.75\t62.2\t55.0\t2757\t5.83\t5.87\t3.64\tFalse\tFalse\tFalse\t...\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tFalse\tTrue\tFalse\n",
    "53940 rows × 24 columns\n",
    "\"\"\"\n",
    "\n",
    "# Değişkenleri belirle:\n",
    "y = df[['price']]\n",
    "x = df.drop('price', axis=1)\n",
    "\n",
    "# Eğitim ve test verilerinin ayrılması:\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.76, random_state=19)\n",
    "\n",
    "# Lineer regresyon modelini kuralım:\n",
    "lm = LinearRegression()\n",
    "model = lm.fit(x_train, y_train)\t# --> eğitim eğitim verileriyle yapılır.\n",
    "\n",
    "# Skoru bulalım:\n",
    "model.score(x_test, y_test)\t\t# --> 0.9200645244634401 --> skor test verileriyle BULUNUR.\n",
    "model.score(x_train, y_train)\t# --> 0.9196844286376016 --> skor eğitim verileriyle BULUNMAZ.\n",
    "\"\"\"\n",
    "NOT1: test verileriyle bulunan skor ile eğitim verileriyle bulunan skor değerleri arasındaki fark ne kadar az ise o kadar uyumlu öğrenmiştir (BALANCED FITTING).\n",
    "NOT2: eğitim verileriyle bulunan skor, test verileriyle bulunan skor değerlerinden ne kadar fazla ise o kadar aşırı öğrenmiştir bildiği verinin cevabını yüksek skorla tahmin eder (OVER FITTING).\n",
    "NOT3: ~0.92 oranında tahmin genel olarak elmas için yetersiz bir doğruluk oranı olarak UNDER FITTING olarak değerlendirilip tahmin skorunun yükseltilmesi için uğraşılmalıdır. Elmas değerli olduğundan yüksek skor gerektirir (UNDER FITTING).\n",
    "\n",
    "Özetle; test verisiyle yapılan skor ne kadar fazla ise o kadar başarılıdır. eğitim verisiyle yani modelin eğitildiği veri ile yapılan skor ne kadar test skorundan uzakta ise o kadar az veya fazla öğrenmiştir.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION:\n",
    "# Lojistik Regresyon 1 ve 0 sonucuna göre sınıflandırma yaparak tercih yapma imkanı sağlar.\n",
    "# P = (e^(ax+b)) / (1+(e^(ax+b)))\n",
    "\n",
    "# DATASET: https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqa2xwaDhGdWFSS2RCb0Q5T2lhNktKdThrckgxZ3xBQ3Jtc0trWGhOUWpXTTZoVTdvTF9uenFoRTVKd1VndmNodXAtR09pUllialJ1SnRRZVFDNHQ4d0FleHllYzVzWHRBTlpCdXdnY3BsZHVTV2RnSW91NlZFcTAyWHFiVkhrWVhDVnpzR3VoeVBrTm93NFZ6MFdxUQ&q=https%3A%2F%2Fwww.kaggle.com%2Fdatasets%2Fuciml%2Fdefault-of-credit-card-clients-dataset&v=XWXZUQAchco\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"UCI_Credit_Card.csv\")\n",
    "df.head(5)\n",
    "\n",
    "# VERİ ÖN İŞLEME: (DATA POST PROCESSING)\n",
    "df = df.drop(\"ID\", axis=1)\n",
    "y = df[\"default.payment.next.month\"]\n",
    "x = df.drop(\"default.payment.next.month\", axis=1)\n",
    "df.shape    # Dafaframe 30000 satır ve 24 sütundan oluşmaktadır.\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.77, random_state=6)\n",
    "log = LogisticRegression()\n",
    "model = log.fit(x_train, y_train)\n",
    "print(\"train skoru: \", model.score(x_train, y_train))\n",
    "print(\"test skoru: \", model.score(x_test, y_test))\n",
    "ornek = x.iloc[1903]        # 1903.satır bilgisini getirir.\n",
    "ornekveri = np.array(ornek)\n",
    "ornekveri\n",
    "model.predict([ornekveri])      # 1903 satırdaki x değişkenleri bilgisi ile modele bir tahmin yaptırılır.\n",
    "y.iloc[1903]        # 1903. satırdaki y değişkeni istenir. Tahmin ile aynı olduğundan model bu veri için başarılıdır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DECISION TREE SINIFLANDIRMA, GRAPHVIZ GÖRSELLEŞTİRME VE RANDOM FOREST SINIFLANDIRMA:\n",
    "# DECISION TREE:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"heart.csv\")\n",
    "df.head()\n",
    "df.info()   # Verilerin tipine bakmak için bilgi komutudur.\n",
    "y = df[\"output\"]\n",
    "x = df.drop(\"output\", axis=1)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "tree = DecisionTreeClassifier()\n",
    "model = tree.fit(x, y)\n",
    "model.score(x, y)       # Sonuç 1 olduğundan aşırıöğrenme durumu vardır. (overfitting)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=16)\n",
    "tree2 = DecisionTreeClassifier()\n",
    "model2 = tree2.fit(x_train, y_train)\n",
    "model2.score(x_test, y_test)\n",
    "x\n",
    "model2.predict([[31,1,2,130,240,0,0,150,0,2,0,0,2]])    # tahmin yapılır.\n",
    "\n",
    "\n",
    "# GRAPHVIZ:\n",
    "import graphviz\n",
    "dot = export_graphviz(model2, feature_names=x.columns, filled=True)\n",
    "gorsel = graphviz.sources.Source(dot)\n",
    "gorsel\n",
    "\n",
    "\n",
    "# RANDOM FOREST:\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier()\n",
    "model3 = forest.fit(x, y)\n",
    "model3.score(x, y)       # OVERFITTING vardır.\n",
    "\n",
    "model4 = forest.fit(x_train, y_train)\n",
    "model4.score(x_test, y_test)\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=300, max_depth=4, criterion='entropy')      # n_estimators: kaç tane ağaç olacak, max_depth: ne kadar derine insin, criterion: hangi kritere göre sınıflandırsın.\n",
    "model5 = forest.fit(x_train, y_train)\n",
    "model5.score(x_test, y_test)\n",
    "\n",
    "\n",
    "# XGB XGBOOSTING SINIFLANDIRMA MODELİ:\n",
    "import xgboost as xgb\n",
    "\n",
    "boost = xgb.XGBClassifier()\n",
    "model3 = boost.fit(x_train, y_train)\n",
    "model3.score(x_test, y_test)\n",
    "\n",
    "insan = df.sample().drop('output', axis=1).values       # sample: dataframeden rastgele veri seçer.\n",
    "model.predict(insan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANDOM FOREST REGRESSOR: SINIFLANDIRMALI REGRESYON MODELİ:\n",
    "'''\n",
    "Sınıflandırma ve regresyon durumu varsa kullanılır. Erkeklerin yaşa göre harcamaları ile Kadınların yaşa göre harcamaları örneğinde\n",
    "Erkekler ile Kadınlar arasında sınıflandırma durumu varken, kendi iç sınıflarında harcama tahmini yapılacağından regresyon vardır.\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('insurance.csv')\n",
    "df.head(3)\n",
    "\n",
    "# Veri Ön İşleme: Verilerin dummy edilmesi (sayısallaştırılması)\n",
    "df = pd.get_dummies(df, columns=['sex', 'smoker', 'region'], drop_first=True)\n",
    "df.head(3)\n",
    "\n",
    "y = df['charges']\n",
    "x = df.drop(columns=['charges'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7, random_state=22)\n",
    "\n",
    "lr = LinearRegression()     # RandomForestRegressor Modelini kıyaslamak için kullanıldı.\n",
    "model = lr.fit(x_train, y_train)\n",
    "model.score(x_test, y_test)\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=200)        # n_estimators: ağaç sayısını belirler.\n",
    "model2 = rf.fit(x_train, y_train)\n",
    "model2.score(x_test, y_test)        # LinearRegression modelinden başarılıdır.\n",
    "\n",
    "x.head(3)       # x değişkenlerinin ilk 3 satırını yazdırdı.\n",
    "model.predict([[31, 23, 2, 1, 1, 1, 0, 0]])     # Tahmin yapıldı.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERİLERİ ÖLÇEKLEME(STANDARD SCALER, MINMAXSCALER):\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "df = pd.read_csv(\"Plane Price.csv\")\n",
    "df.head(3)\n",
    "df.info()\n",
    "\n",
    "df = df[['Rcmnd cruise Knots', 'Stall Knots dirty', 'Fuel gal/lbs', 'Eng out rate of climb', 'Price']]      # Veride çok fazla object olduğu için preprocessing ile uğraşmamak adına sayısal nesnelerden yeni bir dataframe oluşturuldu.\n",
    "df.head(3)\n",
    "df = df.dropna()        # NaN ifadeler olan verileri kaldırır.\n",
    "\n",
    "y = df['Price']\n",
    "x = df.drop(columns=['Price'])\n",
    "\n",
    "# y için normalizasyon yapılmaz!\n",
    "# Bütün sütunlardaki verileri aynı aralıklara getirmek için normalizasyon yapılır.\n",
    "# Outlier(Aykırı değerler) etkisini azaltır.\n",
    "# Model performansı artar.\n",
    "\n",
    "ss = StandardScaler()       # StandardScaler normalizasyonu sütunlardaki verilerin aritmetik ortalamasını 0 a ve standart sapmasını 1 e eşitlicek şekilde verileri ölçekler.\n",
    "x2 = ss.fit_transform(x)\n",
    "x2      # dizi şeklinde verir.\n",
    "x2 = pd.DataFrame(x2)       # diziyi dataframe görünümüne almak için kullanılır.\n",
    "x2.head(3)\n",
    "\"\"\"\n",
    "        0\t        1           2\t         3\n",
    "0\t-1.068341\t-0.904960\t-0.301214\t-1.011179\n",
    "1\t-1.148585\t-1.027513\t-0.306625\t-1.177365\n",
    "2\t-1.198738\t-1.456449\t-0.305594\t-1.403563\n",
    "\"\"\"\n",
    "x2[0].mean()        # 4.633974363652827e-17 =~ 0        (sıfırıncı sütunun aritmetik ortalaması sıfırdır.)\n",
    "x2[0].std()         # 1.0010887319501067 =~ 1           (sıfırıncı sütunun standart sapması birdir.)\n",
    "\n",
    "\n",
    "mm = MinMaxScaler()         # MinMaxScaler normalizasyonu sütundaki verileri belirli iki sayı arasına ölçekler.\n",
    "x3 = mm.fit_transform(x)\n",
    "x3\n",
    "x3 = pd.DataFrame(x3)\n",
    "x3.head(3)\n",
    "\"\"\"\n",
    "        0       \t1       \t2       \t3\n",
    "0\t0.051724\t0.215909\t0.000814\t0.074541\n",
    "1\t0.032020\t0.193182\t0.000102\t0.044254\n",
    "2\t0.019704\t0.113636\t0.000237\t0.003029\n",
    "\"\"\"\n",
    "x3[0].max()         # 1.0 --> herhangi bir sütunun içindeki maksimum veri 1.0 olacak şekilde ölçekler. \n",
    "x3[0].min()         # 0.0 --> herhangi bir sütunun içindeki minimum veri 0.0 olacak şekilde ölçekler.\n",
    "\n",
    "\n",
    "mm2 = MinMaxScaler(feature_range=(2,8))         # MinMaxScaler normalizasyonu sütundaki verileri 2 ve 8 sayıları arasına ölçekler.\n",
    "x4 = mm2.fit_transform(x)\n",
    "x4\n",
    "x4 = pd.DataFrame(x4)\n",
    "x4.head(3)\n",
    "\"\"\"\n",
    "        0\t        1\t        2\t        3\n",
    "0\t2.310345\t3.295455\t2.004883\t2.447249\n",
    "1\t2.192118\t3.159091\t2.000610\t2.265522\n",
    "2\t2.118227\t2.681818\t2.001424\t2.018173\n",
    "\"\"\"\n",
    "x4[0].max()         # 8.0 --> herhangi bir sütunun içindeki maksimum veri 8.0 olacak şekilde ölçekler. \n",
    "x4[0].min()         # 2.0 --> herhangi bir sütunun içindeki minimum veri 2.0 olacak şekilde ölçekler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL ENCODER (KATEGORİK VERİLERİN NUMERİK VERİLERE DÖNÜŞTÜRÜLMESİ):\n",
    "# Kategorisel verileri numerik verilere çeviriyor. ---> ['bjk', 'gs', 'bjk', 'fb'] => [0,1,0,2]\n",
    "# dummy metodundan farklıdır. dummy --> ['bjk', 'gs', 'bjk', 'fb'] => [[1,0,0], [0,1,0], [1,0,0],[0,0,1]]\n",
    "# Bağımlı değişkenlerde(y) kullanılması zordur.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv('Tour_Winners_data_1.csv')\n",
    "df.head(3)\n",
    "\"\"\"\n",
    "\tYear\tTour_No\t    Winner\t        Country\t        Team\t        Tour_overall_length_(km)\tage\t    BMI\t    weight_(Kg)\theight_(m)\trider_type_(PPS)\tclose_rider_type_(PPS)\n",
    "0\t2023\t110\t    Jonas Vingegaard\tDenmark\t    Team Jumbo Visma\t        3406\t            25\t    19.6    \t60.0\t1.749636\tclimber\t                    NaN\n",
    "1\t2022\t109\t    Jonas Vingegaard\tDenmark\t    Team Jumbo Visma\t        3328\t            25\t    19.6    \t60.0\t1.749636\tclimber\t                    NaN\n",
    "2\t2021\t108\t    Tadej Pogacar\t    Slovenia\tUAE Team Emirates\t        3383\t            22\t    21.3    \t66.0\t1.760282\tclimber\t                    NaN\n",
    "\"\"\"\n",
    "df.info()\n",
    "\"\"\"\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 110 entries, 0 to 109\n",
    "Data columns (total 12 columns):\n",
    " #   Column                    Non-Null Count  Dtype  \n",
    "---  ------                    --------------  -----  \n",
    " 0   Year                      110 non-null    int64  \n",
    " 1   Tour_No                   110 non-null    int64  \n",
    " 2   Winner                    110 non-null    object \n",
    " 3   Country                   110 non-null    object \n",
    " 4   Team                      110 non-null    object \n",
    " 5   Tour_overall_length_(km)  110 non-null    object \n",
    " 6   age                       110 non-null    int64  \n",
    " 7   BMI                       70 non-null     float64\n",
    " 8   weight_(Kg)               71 non-null     float64\n",
    " 9   height_(m)                70 non-null     float64\n",
    " 10  rider_type_(PPS)          110 non-null    object \n",
    " 11  close_rider_type_(PPS)    48 non-null     object \n",
    "dtypes: float64(3), int64(3), object(6)\n",
    "memory usage: 10.4+ KB\n",
    "\"\"\"\n",
    "df['Team'].unique()     # Sütundaki verileri listeler.\n",
    "\"\"\"\n",
    "array(['Team Jumbo Visma', 'UAE Team Emirates', 'Team Ineos ', 'Team Sky',\n",
    "       'Astana Pro Team', 'BMC Racing Team', 'Team Saxo Bank', 'Astana',\n",
    "       'Team CSC Saxo Bank', 'Discovery Channel', \"Caisse d'Epargne\",\n",
    "       'US Postal Service', 'Mercatone Uno', 'Telekom', 'Banesto',\n",
    "       'Z Tomasso', 'ADR', 'Reynolds', 'Carrera', 'La Vie Claire',\n",
    "       'Renault', 'TI Raleigh', 'Peugeot', 'Gitane', 'Molteni', 'Bic',\n",
    "       'Faemino', 'Faema', 'Holland', 'France', 'Ford', 'Salvarini',\n",
    "       'St-Raphael', 'Italy', 'Spain', 'Holland Luxembourg',\n",
    "       'Nord Est Centre', 'Switzerland', 'Ouest', 'Belgium', 'Alcyon',\n",
    "       'Automoto', 'Cycles Peugeot', 'La Sportive', 'Alycon', 'Cycles JC',\n",
    "       'La Francaise'], dtype=object)\n",
    "\"\"\"\n",
    "\n",
    "le = LabelEncoder()     # Kategorik verileri numerik verilere dönüştürür.\n",
    "le.fit(df['Team'])      # Verilen sütun verilerini numerik verilere eşitler.\n",
    "x = le.transform(df['Team'])    # Verilen sütun verilerini numerik verilere dönüştürür.\n",
    "\n",
    "le.classes_         # Dönüştürülen verilerin alfabetik sıralamasını verir.\n",
    "\"\"\"\n",
    "array(['ADR', 'Alcyon', 'Alycon', 'Astana', 'Astana Pro Team', 'Automoto',\n",
    "       'BMC Racing Team', 'Banesto', 'Belgium', 'Bic', \"Caisse d'Epargne\",\n",
    "       'Carrera', 'Cycles JC', 'Cycles Peugeot', 'Discovery Channel',\n",
    "       'Faema', 'Faemino', 'Ford', 'France', 'Gitane', 'Holland',\n",
    "       'Holland Luxembourg', 'Italy', 'La Francaise', 'La Sportive',\n",
    "       'La Vie Claire', 'Mercatone Uno', 'Molteni', 'Nord Est Centre',\n",
    "       'Ouest', 'Peugeot', 'Renault', 'Reynolds', 'Salvarini', 'Spain',\n",
    "       'St-Raphael', 'Switzerland', 'TI Raleigh', 'Team CSC Saxo Bank',\n",
    "       'Team Ineos ', 'Team Jumbo Visma', 'Team Saxo Bank', 'Team Sky',\n",
    "       'Telekom', 'UAE Team Emirates', 'US Postal Service', 'Z Tomasso'],\n",
    "      dtype=object)\n",
    "\"\"\"\n",
    "\n",
    "le.inverse_transform(x)     # Numerik verilere dönüştürülen verilerin Kategorik verilere geri dönüştürülmesini sağlar.\n",
    "\"\"\"\n",
    "array(['Team Jumbo Visma', 'Team Jumbo Visma', 'UAE Team Emirates',\n",
    "       'UAE Team Emirates', 'Team Ineos ', 'Team Sky', 'Team Sky',\n",
    "       'Team Sky', 'Team Sky', 'Astana Pro Team', 'Team Sky', 'Team Sky',\n",
    "       'BMC Racing Team', 'Team Saxo Bank', 'Astana',\n",
    "       'Team CSC Saxo Bank', 'Discovery Channel', \"Caisse d'Epargne\",\n",
    "       'Discovery Channel', 'US Postal Service', 'US Postal Service',\n",
    "       'US Postal Service', 'US Postal Service', 'US Postal Service',\n",
    "       'US Postal Service', 'Mercatone Uno', 'Telekom', 'Telekom',\n",
    "       'Banesto', 'Banesto', 'Banesto', 'Banesto', 'Banesto', 'Z Tomasso',\n",
    "       'ADR', 'Reynolds', 'Carrera', 'La Vie Claire', 'La Vie Claire',\n",
    "       'Renault', 'Renault', 'Renault', 'Renault', 'TI Raleigh',\n",
    "       'Renault', 'Renault', 'Peugeot', 'Gitane', 'Peugeot', 'Molteni',\n",
    "       'Bic', 'Molteni', 'Molteni', 'Faemino', 'Faema', 'Holland',\n",
    "       'France', 'Ford', 'Salvarini', 'St-Raphael', 'St-Raphael',\n",
    "       'St-Raphael', 'France', 'Italy', 'Spain', 'Holland Luxembourg',\n",
    "       'France', 'Nord Est Centre', 'France', 'France', 'France', 'Italy',\n",
    "       'Switzerland', 'Switzerland', 'Italy', 'Italy', 'Ouest', 'Belgium',\n",
    "       'Italy', 'France', 'Belgium', 'Belgium', 'France', 'France',\n",
    "       'France', 'France', 'France', 'Alcyon', 'Alcyon', 'Alcyon',\n",
    "       'Automoto', 'Automoto', 'Automoto', 'Automoto', 'Cycles Peugeot',\n",
    "       'La Sportive', 'La Sportive', 'La Sportive', 'Cycles Peugeot',\n",
    "       'Cycles Peugeot', 'Alycon', 'Alycon', 'Alycon', 'Alycon',\n",
    "       'Cycles Peugeot', 'Cycles Peugeot', 'Cycles Peugeot',\n",
    "       'Cycles Peugeot', 'Cycles JC', 'La Francaise'], dtype=object)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
